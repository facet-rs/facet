//! Generate benchmark code from benchmarks.kdl definitions.
//!
//! This ensures every benchmark has BOTH divan (wall-clock) AND gungraun (instruction count) versions
//! for ALL 4 targets:
//!   - serde_json: baseline
//!   - facet_format_json: no JIT (reflection only)
//!   - facet_format_jit_t1: Tier-1 JIT only (shape-based)
//!   - facet_format_jit_t2: Tier-2 JIT (format-specific, falls back to Tier-1)

use benchmark_defs::{BenchmarkDef, TypeDef};
use std::env;
use std::fs;
use std::path::{Path, PathBuf};

fn main() {
    let args: Vec<String> = env::args().skip(1).collect();

    // Find workspace root by looking for Cargo.toml with [workspace]
    let workspace_root = find_workspace_root().unwrap_or_else(|| {
        eprintln!("Could not find workspace root");
        std::process::exit(1);
    });

    let kdl_path = args
        .first()
        .map(PathBuf::from)
        .unwrap_or_else(|| workspace_root.join("facet-json/benches/benchmarks.kdl"));

    let divan_path = workspace_root.join("facet-json/benches/unified_benchmarks_divan.rs");
    let gungraun_path = workspace_root.join("facet-json/benches/unified_benchmarks_gungraun.rs");
    let tests_path = workspace_root.join("facet-json/tests/generated_benchmark_tests.rs");

    match generate_benchmarks(
        &kdl_path,
        &divan_path,
        &gungraun_path,
        &tests_path,
        &workspace_root,
    ) {
        Ok(()) => {
            println!("\nðŸŽ‰ Success!");
            println!("Run benchmarks with:");
            println!("   cargo bench --bench unified_benchmarks_divan --features jit");
            println!("   cargo bench --bench unified_benchmarks_gungraun --features jit");
            println!("Run tests (for debugging with valgrind):");
            println!("   cargo nextest run -p facet-json generated_benchmark_tests --features jit");
        }
        Err(e) => {
            eprintln!("âŒ Error generating benchmarks: {}", e);
            std::process::exit(1);
        }
    }
}

fn find_workspace_root() -> Option<PathBuf> {
    let mut current = env::current_dir().ok()?;
    loop {
        let cargo_toml = current.join("Cargo.toml");
        if cargo_toml.exists()
            && let Ok(content) = fs::read_to_string(&cargo_toml)
            && content.contains("[workspace]")
        {
            return Some(current);
        }
        if !current.pop() {
            return None;
        }
    }
}

fn generate_benchmarks(
    kdl_path: &Path,
    divan_output_path: &Path,
    gungraun_output_path: &Path,
    tests_output_path: &Path,
    workspace_root: &Path,
) -> Result<(), Box<dyn std::error::Error>> {
    println!(
        "ðŸ“– Reading benchmark definitions from {}",
        kdl_path.display()
    );

    let file = match benchmark_defs::parse_benchmarks(kdl_path) {
        Ok(f) => f,
        Err(e) => {
            eprintln!("âŒ Failed to parse KDL:");
            eprintln!("{:?}", e);
            return Err(e);
        }
    };

    let benchmarks = file.benchmarks;
    let type_defs = file.type_defs;

    println!("   Found {} benchmarks", benchmarks.len());
    println!("   Found {} type definitions", type_defs.len());

    // Generate DIVAN benchmarks
    let divan_output = generate_divan_benchmarks(&benchmarks, &type_defs, workspace_root)?;
    println!(
        "âœï¸  Writing divan benchmarks to {}",
        divan_output_path.display()
    );
    fs::write(divan_output_path, divan_output)?;

    // Generate GUNGRAUN benchmarks
    let gungraun_output = generate_gungraun_benchmarks(&benchmarks, &type_defs, workspace_root)?;
    println!(
        "âœï¸  Writing gungraun benchmarks to {}",
        gungraun_output_path.display()
    );
    fs::write(gungraun_output_path, gungraun_output)?;

    // Generate TESTS (for valgrind debugging)
    let tests_output = generate_tests(&benchmarks, &type_defs, workspace_root)?;
    println!("âœï¸  Writing tests to {}", tests_output_path.display());
    fs::write(tests_output_path, tests_output)?;

    println!(
        "âœ… Generated {} benchmarks Ã— 3 targets Ã— 2 harnesses = {} total benchmark functions!",
        benchmarks.len(),
        benchmarks.len() * 3 * 2
    );
    println!(
        "âœ… Generated {} test modules for valgrind debugging!",
        benchmarks.len()
    );

    Ok(())
}

fn generate_divan_benchmarks(
    benchmarks: &[BenchmarkDef],
    type_defs: &[TypeDef],
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut output = String::new();

    // File header
    output.push_str("//! AUTO-GENERATED by benchmark-generator\n");
    output.push_str("//! DO NOT EDIT - Edit facet-json/benches/benchmarks.kdl instead\n");
    output.push_str("//!\n");
    output.push_str(
        "//! This file ensures parity: every benchmark has BOTH divan AND gungraun versions\n",
    );
    output.push_str("//! for ALL 3 targets: serde_json, facet_format_json, facet_format_jit.\n\n");
    output.push_str("#![allow(clippy::explicit_auto_deref)]\n\n");

    // Imports
    output.push_str("use facet::Facet;\n");
    output.push_str("#[cfg(feature = \"jit\")]\n");
    output.push_str("use facet_format::jit as format_jit;\n");
    output.push_str("#[cfg(feature = \"jit\")]\n");
    output.push_str("use facet_format_json::JsonParser;\n");
    output.push_str("use divan::Bencher;\n");
    output.push_str("use std::hint::black_box;\n\n");

    // Type definitions
    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str("// Type Definitions\n");
    output.push_str(
        "// ============================================================================\n\n",
    );

    for type_def in type_defs {
        output.push_str(&type_def.code.content);
        output.push_str("\n\n");
    }

    // Generate only DIVAN benchmark modules
    for bench_def in benchmarks {
        output.push_str(&generate_divan_benchmark_module(bench_def, workspace_root)?);
    }

    // Entry point for divan harness
    output.push_str("fn main() {\n");
    output.push_str("    divan::main();\n");
    output.push_str("}\n");

    Ok(output)
}

fn generate_gungraun_benchmarks(
    benchmarks: &[BenchmarkDef],
    type_defs: &[TypeDef],
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut output = String::new();

    // File header
    output.push_str("//! AUTO-GENERATED by benchmark-generator\n");
    output.push_str("//! DO NOT EDIT - Edit facet-json/benches/benchmarks.kdl instead\n");
    output.push_str("//!\n");
    output.push_str("//! Gungraun benchmarks (instruction counts)\n");
    output.push_str("//! Targets: serde_json, facet_format_json, facet_format_jit\n\n");
    output.push_str("#![allow(clippy::explicit_auto_deref)]\n\n");

    // Imports
    output.push_str("use facet::Facet;\n");
    output.push_str("#[cfg(feature = \"jit\")]\n");
    output.push_str("use facet_format::jit as format_jit;\n");
    output.push_str("#[cfg(feature = \"jit\")]\n");
    output.push_str("use facet_format_json::JsonParser;\n");
    output.push_str("use std::hint::black_box;\n\n");

    // Type definitions
    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str("// Type Definitions\n");
    output.push_str(
        "// ============================================================================\n\n",
    );

    for type_def in type_defs {
        output.push_str(&type_def.code.content);
        output.push_str("\n\n");
    }

    // Generate only GUNGRAUN benchmark modules
    for bench_def in benchmarks {
        output.push_str(&generate_gungraun_benchmark_module(
            bench_def,
            workspace_root,
        )?);
    }

    // Generate gungraun groups
    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str("// Gungraun Benchmark Groups\n");
    output.push_str(
        "// ============================================================================\n\n",
    );

    // Re-export gungraun benchmarks at module level for macro compatibility
    output.push_str("// Re-export gungraun DESERIALIZE benchmarks\n");
    for bench_def in benchmarks {
        output.push_str(&format!(
            "use {}::gungraun_{}_serde_json_deserialize;\n",
            bench_def.name, bench_def.name
        ));
        output.push_str(&format!(
            "use {}::gungraun_{}_facet_format_json_deserialize;\n",
            bench_def.name, bench_def.name
        ));
        output.push_str("#[cfg(feature = \"jit\")]\n");
        output.push_str(&format!(
            "use {}::gungraun_{}_facet_format_jit_t1_deserialize;\n",
            bench_def.name, bench_def.name
        ));
        output.push_str("#[cfg(feature = \"jit\")]\n");
        output.push_str(&format!(
            "use {}::gungraun_{}_facet_format_jit_t2_deserialize;\n",
            bench_def.name, bench_def.name
        ));
    }
    output.push('\n');

    output.push_str("// Re-export gungraun SERIALIZE benchmarks\n");
    for bench_def in benchmarks {
        output.push_str(&format!(
            "use {}::gungraun_{}_serde_json_serialize;\n",
            bench_def.name, bench_def.name
        ));
        output.push_str(&format!(
            "use {}::gungraun_{}_facet_format_json_serialize;\n",
            bench_def.name, bench_def.name
        ));
    }
    output.push('\n');

    // Deserialize groups
    for bench_def in benchmarks {
        // Non-JIT group
        output.push_str("#[cfg(not(feature = \"jit\"))]\n");
        output.push_str(&format!(
            "gungraun::library_benchmark_group!(\n    name = {}_deser;\n    benchmarks =\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_serde_json_deserialize,\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_facet_format_json_deserialize\n",
            bench_def.name
        ));
        output.push_str(");\n\n");

        // JIT group
        output.push_str("#[cfg(feature = \"jit\")]\n");
        output.push_str(&format!(
            "gungraun::library_benchmark_group!(\n    name = {}_deser;\n    benchmarks =\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_serde_json_deserialize,\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_facet_format_json_deserialize,\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_facet_format_jit_t1_deserialize,\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_facet_format_jit_t2_deserialize\n",
            bench_def.name
        ));
        output.push_str(");\n\n");
    }

    // Serialize groups (no JIT for serialize yet)
    for bench_def in benchmarks {
        output.push_str(&format!(
            "gungraun::library_benchmark_group!(\n    name = {}_ser;\n    benchmarks =\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_serde_json_serialize,\n",
            bench_def.name
        ));
        output.push_str(&format!(
            "        gungraun_{}_facet_format_json_serialize\n",
            bench_def.name
        ));
        output.push_str(");\n\n");
    }

    // Main gungraun entry point
    output.push_str("// Gungraun main\n");
    output.push_str("gungraun::main!(\n    library_benchmark_groups =\n");
    for (i, bench_def) in benchmarks.iter().enumerate() {
        if i > 0 {
            output.push_str(",\n");
        }
        output.push_str(&format!(
            "        {}_deser,\n        {}_ser",
            bench_def.name, bench_def.name
        ));
    }
    output.push_str("\n);\n");

    Ok(output)
}

fn generate_divan_benchmark_module(
    bench_def: &BenchmarkDef,
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut output = String::new();

    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str(&format!("// BENCHMARK: {}\n", bench_def.name));
    output.push_str(
        "// ============================================================================\n\n",
    );

    output.push_str(&format!("mod {} {{\n", bench_def.name));
    output.push_str("    use super::*;\n");
    output.push_str("    use std::sync::LazyLock;\n\n");

    let is_brotli = bench_def.json_brotli.is_some();

    if is_brotli {
        // Brotli-compressed data: use include_bytes! + LazyLock for decompression
        let brotli_path = bench_def.json_brotli.as_ref().unwrap();
        output.push_str(&format!(
            "    static COMPRESSED: &[u8] = include_bytes!(\"../../tools/benchmark-generator/{}\");\n\n",
            brotli_path.path
        ));
        output.push_str("    static JSON: LazyLock<Vec<u8>> = LazyLock::new(|| {\n");
        output.push_str("        let mut decompressed = Vec::new();\n");
        output.push_str("        brotli::BrotliDecompress(&mut std::io::Cursor::new(COMPRESSED), &mut decompressed).unwrap();\n");
        output.push_str("        decompressed\n");
        output.push_str("    });\n\n");
    } else {
        // Inline or file-based JSON: embed directly
        let json_content = get_json_content(bench_def, workspace_root)?;
        output.push_str(&format!(
            "    static JSON: &[u8] = br#\"{}\"#;\n\n",
            json_content
        ));
    }

    // Pre-deserialize data for serialization benchmarks
    let json_ref_for_deser = if is_brotli { "&*JSON" } else { "JSON" };
    output.push_str(&format!(
        "    static DATA: LazyLock<{}> = LazyLock::new(|| serde_json::from_slice({}).unwrap());\n\n",
        bench_def.type_name, json_ref_for_deser
    ));

    // DIVAN DESERIALIZE benchmarks
    output.push_str("    // ===== DIVAN DESERIALIZE =====\n\n");

    let json_ref = if is_brotli { "json.as_slice()" } else { "JSON" };

    // 1. serde_json (baseline)
    output.push_str("    #[divan::bench]\n");
    output.push_str("    fn serde_json_deserialize(bencher: Bencher) {\n");
    if is_brotli {
        output.push_str("        let json = &*JSON;\n");
        output.push_str("        bencher.bench(|| {\n");
        output.push_str(&format!(
            "            black_box(serde_json::from_slice::<{}>(black_box(json.as_slice())).unwrap())\n",
            bench_def.type_name
        ));
    } else {
        output.push_str("        bencher.bench(|| {\n");
        output.push_str(&format!(
            "            black_box(serde_json::from_slice::<{}>(black_box(JSON)).unwrap())\n",
            bench_def.type_name
        ));
    }
    output.push_str("        });\n");
    output.push_str("    }\n\n");

    // 2. facet_format_json (no JIT)
    output.push_str("    #[divan::bench]\n");
    output.push_str("    fn facet_format_json_deserialize(bencher: Bencher) {\n");
    if is_brotli {
        output.push_str("        let json = &*JSON;\n");
        output.push_str("        bencher.bench(|| {\n");
        output.push_str(&format!(
            "            black_box(facet_format_json::from_slice::<{}>(black_box(json.as_slice())).unwrap())\n",
            bench_def.type_name
        ));
    } else {
        output.push_str("        bencher.bench(|| {\n");
        output.push_str(&format!(
            "            black_box(facet_format_json::from_slice::<{}>(black_box(JSON)).unwrap())\n",
            bench_def.type_name
        ));
    }
    output.push_str("        });\n");
    output.push_str("    }\n\n");

    // 3. facet_format_jit_t1 (Tier-1 only: shape-based JIT, falls back to reflection)
    output.push_str("    #[cfg(feature = \"jit\")]\n");
    output.push_str("    #[divan::bench]\n");
    output.push_str("    fn facet_format_jit_t1_deserialize(bencher: Bencher) {\n");
    if is_brotli {
        output.push_str("        let json = &*JSON;\n");
    }
    output.push_str("        bencher.bench(|| {\n");
    output.push_str(&format!(
        "            black_box(format_jit::deserialize_with_fallback::<{}, _>(JsonParser::new(black_box({}))).unwrap())\n",
        bench_def.type_name, json_ref
    ));
    output.push_str("        });\n");
    output.push_str("    }\n\n");

    // 4. facet_format_jit_t2 (Tier-2 first, then Tier-1, then reflection)
    output.push_str("    #[cfg(feature = \"jit\")]\n");
    output.push_str("    #[divan::bench]\n");
    output.push_str("    fn facet_format_jit_t2_deserialize(bencher: Bencher) {\n");
    if is_brotli {
        output.push_str("        let json = &*JSON;\n");
    }
    output.push_str("        // Reset tier stats before benchmark\n");
    output.push_str("        format_jit::reset_tier_stats();\n");
    output.push_str("        bencher.bench(|| {\n");
    output.push_str(&format!(
        "            black_box(format_jit::deserialize_with_format_jit_fallback::<{}, _>(JsonParser::new(black_box({}))).unwrap())\n",
        bench_def.type_name, json_ref
    ));
    output.push_str("        });\n");
    output.push_str("        // Capture tier stats after benchmark\n");
    output.push_str(
        "        let (t2_attempts, t2_successes, _, _, _, t1_fallbacks) = format_jit::get_tier_stats();\n",
    );
    output.push_str(&format!(
        "        eprintln!(\"[TIER_STATS] benchmark={} target=facet_format_jit_t2 operation=deserialize tier2_attempts={{}} tier2_successes={{}} tier1_fallbacks={{}}\", t2_attempts, t2_successes, t1_fallbacks);\n",
        bench_def.name
    ));
    output.push_str("    }\n\n");

    // DIVAN SERIALIZE benchmarks
    output.push_str("    // ===== DIVAN SERIALIZE =====\n\n");

    // serde_json serialize
    output.push_str("    #[divan::bench]\n");
    output.push_str("    fn serde_json_serialize(bencher: Bencher) {\n");
    output.push_str("        let data = &*DATA;\n");
    output.push_str("        bencher.bench(|| {\n");
    output.push_str("            black_box(serde_json::to_string(black_box(data)).unwrap())\n");
    output.push_str("        });\n");
    output.push_str("    }\n\n");

    // facet_format_json serialize
    output.push_str("    #[divan::bench]\n");
    output.push_str("    fn facet_format_json_serialize(bencher: Bencher) {\n");
    output.push_str("        let data = &*DATA;\n");
    output.push_str("        bencher.bench(|| {\n");
    output.push_str(
        "            black_box(facet_format_json::to_string(black_box(data)).unwrap())\n",
    );
    output.push_str("        });\n");
    output.push_str("    }\n\n");

    output.push_str("}\n\n");
    Ok(output)
}

fn generate_gungraun_benchmark_module(
    bench_def: &BenchmarkDef,
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut output = String::new();

    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str(&format!("// BENCHMARK: {}\n", bench_def.name));
    output.push_str(
        "// ============================================================================\n\n",
    );

    output.push_str(&format!("mod {} {{\n", bench_def.name));
    output.push_str("    use super::*;\n");
    output.push_str("    use std::sync::LazyLock;\n\n");

    let is_brotli = bench_def.json_brotli.is_some();

    if is_brotli {
        // Brotli-compressed data: use include_bytes! + LazyLock for decompression
        let brotli_path = bench_def.json_brotli.as_ref().unwrap();
        output.push_str(&format!(
            "    static COMPRESSED: &[u8] = include_bytes!(\"../../tools/benchmark-generator/{}\");\n\n",
            brotli_path.path
        ));
        output.push_str("    static JSON: LazyLock<Vec<u8>> = LazyLock::new(|| {\n");
        output.push_str("        let mut decompressed = Vec::new();\n");
        output.push_str("        brotli::BrotliDecompress(&mut std::io::Cursor::new(COMPRESSED), &mut decompressed).unwrap();\n");
        output.push_str("        decompressed\n");
        output.push_str("    });\n\n");
    } else {
        // Inline or file-based JSON: embed directly
        let json_content = get_json_content(bench_def, workspace_root)?;
        output.push_str(&format!(
            "    static JSON: &[u8] = br#\"{}\"#;\n\n",
            json_content
        ));
    }

    // Pre-deserialize data for serialization benchmarks
    let json_ref_for_deser = if is_brotli { "&*JSON" } else { "JSON" };
    output.push_str(&format!(
        "    static DATA: LazyLock<{}> = LazyLock::new(|| serde_json::from_slice({}).unwrap());\n\n",
        bench_def.type_name, json_ref_for_deser
    ));

    // GUNGRAUN DESERIALIZE benchmarks
    output.push_str("    // ===== GUNGRAUN DESERIALIZE =====\n\n");

    let json_ref = if is_brotli { "&*JSON" } else { "JSON" };

    // serde_json
    output.push_str("    #[gungraun::library_benchmark]\n");
    output.push_str(&format!(
        "    pub fn gungraun_{}_serde_json_deserialize() -> {} {{\n",
        bench_def.name, bench_def.type_name
    ));
    output.push_str(&format!(
        "        black_box(serde_json::from_slice::<{}>(black_box({})).unwrap())\n",
        bench_def.type_name, json_ref
    ));
    output.push_str("    }\n\n");

    // facet_format_json
    output.push_str("    #[gungraun::library_benchmark]\n");
    output.push_str(&format!(
        "    pub fn gungraun_{}_facet_format_json_deserialize() -> {} {{\n",
        bench_def.name, bench_def.type_name
    ));
    output.push_str(&format!(
        "        black_box(facet_format_json::from_slice::<{}>(black_box({})).unwrap())\n",
        bench_def.type_name, json_ref
    ));
    output.push_str("    }\n\n");

    // JIT T1 setup and benchmark (Tier-1 only: shape-based JIT)
    if is_brotli {
        output.push_str("    #[cfg(feature = \"jit\")]\n");
        output.push_str("    fn setup_jit_t1() -> &'static [u8] {\n");
        output.push_str(
            "        let json: &'static [u8] = Box::leak(JSON.clone().into_boxed_slice());\n",
        );
        output.push_str(&format!(
            "        let _ = format_jit::deserialize_with_fallback::<{}, _>(JsonParser::new(json));\n",
            bench_def.type_name
        ));
        output.push_str("        json\n");
        output.push_str("    }\n\n");
    } else {
        output.push_str("    #[cfg(feature = \"jit\")]\n");
        output.push_str("    fn setup_jit_t1() -> &'static [u8] {\n");
        output.push_str(&format!(
            "        let _ = format_jit::deserialize_with_fallback::<{}, _>(JsonParser::new(JSON));\n",
            bench_def.type_name
        ));
        output.push_str("        JSON\n");
        output.push_str("    }\n\n");
    }

    output.push_str("    #[cfg(feature = \"jit\")]\n");
    output.push_str("    #[gungraun::library_benchmark]\n");
    output.push_str("    #[bench::cached(setup = setup_jit_t1)]\n");
    output.push_str(&format!(
        "    pub fn gungraun_{}_facet_format_jit_t1_deserialize(json: &[u8]) -> {} {{\n",
        bench_def.name, bench_def.type_name
    ));
    output.push_str("        let parser = JsonParser::new(black_box(json));\n");
    output.push_str(&format!(
        "        black_box(format_jit::deserialize_with_fallback::<{}, _>(parser).unwrap())\n",
        bench_def.type_name
    ));
    output.push_str("    }\n\n");

    // JIT T2 setup and benchmark (Tier-2 first, then Tier-1, then reflection)
    if is_brotli {
        output.push_str("    #[cfg(feature = \"jit\")]\n");
        output.push_str("    fn setup_jit_t2() -> &'static [u8] {\n");
        output.push_str(
            "        let json: &'static [u8] = Box::leak(JSON.clone().into_boxed_slice());\n",
        );
        output.push_str("        // Reset and capture tier stats during warmup\n");
        output.push_str("        format_jit::reset_tier_stats();\n");
        output.push_str("        let mut parser = JsonParser::new(json);\n");
        output.push_str(&format!(
            "        let _ = format_jit::try_deserialize_with_format_jit::<{}, _>(&mut parser);\n",
            bench_def.type_name
        ));
        output.push_str("        let (t2_attempts, t2_successes, _, _, _, t1_fallbacks) = format_jit::get_tier_stats();\n");
        output.push_str(&format!(
            "        eprintln!(\"[TIER_STATS] benchmark={} target=facet_format_jit_t2 operation=deserialize tier2_attempts={{}} tier2_successes={{}} tier1_fallbacks={{}}\", t2_attempts, t2_successes, t1_fallbacks);\n",
            bench_def.name
        ));
        output.push_str("        json\n");
        output.push_str("    }\n\n");
    } else {
        output.push_str("    #[cfg(feature = \"jit\")]\n");
        output.push_str("    fn setup_jit_t2() -> &'static [u8] {\n");
        output.push_str("        // Reset and capture tier stats during warmup\n");
        output.push_str("        format_jit::reset_tier_stats();\n");
        output.push_str("        let mut parser = JsonParser::new(JSON);\n");
        output.push_str(&format!(
            "        let _ = format_jit::try_deserialize_with_format_jit::<{}, _>(&mut parser);\n",
            bench_def.type_name
        ));
        output.push_str("        let (t2_attempts, t2_successes, _, _, _, t1_fallbacks) = format_jit::get_tier_stats();\n");
        output.push_str(&format!(
            "        eprintln!(\"[TIER_STATS] benchmark={} target=facet_format_jit_t2 operation=deserialize tier2_attempts={{}} tier2_successes={{}} tier1_fallbacks={{}}\", t2_attempts, t2_successes, t1_fallbacks);\n",
            bench_def.name
        ));
        output.push_str("        JSON\n");
        output.push_str("    }\n\n");
    }

    output.push_str("    #[cfg(feature = \"jit\")]\n");
    output.push_str("    #[gungraun::library_benchmark]\n");
    output.push_str("    #[bench::cached(setup = setup_jit_t2)]\n");
    output.push_str(&format!(
        "    pub fn gungraun_{}_facet_format_jit_t2_deserialize(json: &[u8]) -> {} {{\n",
        bench_def.name, bench_def.type_name
    ));
    output.push_str("        let parser = JsonParser::new(black_box(json));\n");
    output.push_str(&format!(
        "        black_box(format_jit::deserialize_with_format_jit_fallback::<{}, _>(parser).unwrap())\n",
        bench_def.type_name
    ));
    output.push_str("    }\n\n");

    // GUNGRAUN SERIALIZE benchmarks
    output.push_str("    // ===== GUNGRAUN SERIALIZE =====\n\n");

    // Setup for serialization - get static reference to data
    output.push_str(&format!(
        "    fn setup_serialize() -> &'static {} {{\n",
        bench_def.type_name
    ));
    output.push_str("        &*DATA\n");
    output.push_str("    }\n\n");

    // serde_json serialize
    output.push_str("    #[gungraun::library_benchmark]\n");
    output.push_str("    #[bench::cached(setup = setup_serialize)]\n");
    output.push_str(&format!(
        "    pub fn gungraun_{}_serde_json_serialize(data: &{}) -> String {{\n",
        bench_def.name, bench_def.type_name
    ));
    output.push_str("        black_box(serde_json::to_string(black_box(data)).unwrap())\n");
    output.push_str("    }\n\n");

    // facet_format_json serialize
    output.push_str("    #[gungraun::library_benchmark]\n");
    output.push_str("    #[bench::cached(setup = setup_serialize)]\n");
    output.push_str(&format!(
        "    pub fn gungraun_{}_facet_format_json_serialize(data: &{}) -> String {{\n",
        bench_def.name, bench_def.type_name
    ));
    output.push_str("        black_box(facet_format_json::to_string(black_box(data)).unwrap())\n");
    output.push_str("    }\n\n");

    output.push_str("}\n\n");
    Ok(output)
}

fn generate_tests(
    benchmarks: &[BenchmarkDef],
    type_defs: &[TypeDef],
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut output = String::new();

    // File header
    output.push_str("//! AUTO-GENERATED by benchmark-generator\n");
    output.push_str("//! DO NOT EDIT - Edit facet-json/benches/benchmarks.kdl instead\n");
    output.push_str("//!\n");
    output.push_str(
        "//! These tests mirror the benchmarks and can be run under valgrind for debugging.\n",
    );
    output.push_str("//! Run with: valgrind cargo test -p facet-json generated_benchmark_tests --features jit -- --test-threads=1\n\n");
    output.push_str("#![allow(clippy::explicit_auto_deref)]\n\n");

    // Imports
    output.push_str("use facet::Facet;\n");
    output.push_str("#[cfg(feature = \"jit\")]\n");
    output.push_str("use facet_format::jit as format_jit;\n");
    output.push_str("#[cfg(feature = \"jit\")]\n");
    output.push_str("use facet_format_json::JsonParser;\n\n");

    // Type definitions
    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str("// Type Definitions\n");
    output.push_str(
        "// ============================================================================\n\n",
    );

    for type_def in type_defs {
        output.push_str(&type_def.code.content);
        output.push_str("\n\n");
    }

    // Generate test modules
    for bench_def in benchmarks {
        output.push_str(&generate_test_module(bench_def, workspace_root)?);
    }

    Ok(output)
}

fn generate_test_module(
    bench_def: &BenchmarkDef,
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    let mut output = String::new();

    output.push_str(
        "// ============================================================================\n",
    );
    output.push_str(&format!("// TESTS: {}\n", bench_def.name));
    output.push_str(
        "// ============================================================================\n\n",
    );

    output.push_str(&format!("mod test_{} {{\n", bench_def.name));
    output.push_str("    #[allow(unused_imports)]\n");
    output.push_str("    use super::*;\n");
    output.push_str("    use std::sync::LazyLock;\n\n");

    let is_brotli = bench_def.json_brotli.is_some();

    if is_brotli {
        let brotli_path = bench_def.json_brotli.as_ref().unwrap();
        output.push_str(&format!(
            "    static COMPRESSED: &[u8] = include_bytes!(\"../../tools/benchmark-generator/{}\");\n\n",
            brotli_path.path
        ));
        output.push_str("    static JSON: LazyLock<Vec<u8>> = LazyLock::new(|| {\n");
        output.push_str("        let mut decompressed = Vec::new();\n");
        output.push_str("        brotli::BrotliDecompress(&mut std::io::Cursor::new(COMPRESSED), &mut decompressed).unwrap();\n");
        output.push_str("        decompressed\n");
        output.push_str("    });\n\n");
    } else {
        let json_content = get_json_content(bench_def, workspace_root)?;
        output.push_str(&format!(
            "    static JSON: &[u8] = br#\"{}\"#;\n\n",
            json_content
        ));
    }

    // Pre-deserialize data for serialization tests
    let json_ref_for_deser = if is_brotli { "&*JSON" } else { "JSON" };
    output.push_str(&format!(
        "    static DATA: LazyLock<{}> = LazyLock::new(|| serde_json::from_slice({}).unwrap());\n\n",
        bench_def.type_name, json_ref_for_deser
    ));

    let json_ref = if is_brotli { "&*JSON" } else { "JSON" };

    // DESERIALIZE tests
    output.push_str("    // ===== DESERIALIZE TESTS =====\n\n");

    // serde_json test
    output.push_str("    #[test]\n");
    output.push_str("    fn test_serde_json_deserialize() {\n");
    output.push_str(&format!(
        "        let result = serde_json::from_slice::<{}>({});\n",
        bench_def.type_name, json_ref
    ));
    output.push_str(
        "        assert!(result.is_ok(), \"serde_json deserialize failed: {:?}\", result.err());\n",
    );
    output.push_str("    }\n\n");

    // facet_format_json test
    output.push_str("    #[test]\n");
    output.push_str("    fn test_facet_format_json_deserialize() {\n");
    output.push_str(&format!(
        "        let result = facet_format_json::from_slice::<{}>({});\n",
        bench_def.type_name, json_ref
    ));
    output.push_str("        assert!(result.is_ok(), \"facet_format_json deserialize failed: {:?}\", result.err());\n");
    output.push_str("    }\n\n");

    // JIT T1 deserialize test (Tier-1 only)
    output.push_str("    #[cfg(feature = \"jit\")]\n");
    output.push_str("    #[test]\n");
    output.push_str("    fn test_facet_format_jit_t1_deserialize() {\n");
    output.push_str(&format!(
        "        let result = format_jit::deserialize_with_fallback::<{}, _>(JsonParser::new({}));\n",
        bench_def.type_name, json_ref
    ));
    output.push_str(
        "        assert!(result.is_ok(), \"JIT T1 deserialize failed: {:?}\", result.err());\n",
    );
    output.push_str("    }\n\n");

    // JIT T2 deserialize test (Tier-2 first, then fallback)
    output.push_str("    #[cfg(feature = \"jit\")]\n");
    output.push_str("    #[test]\n");
    output.push_str("    fn test_facet_format_jit_t2_deserialize() {\n");
    output.push_str(&format!(
        "        let result = format_jit::deserialize_with_format_jit_fallback::<{}, _>(JsonParser::new({}));\n",
        bench_def.type_name, json_ref
    ));
    output.push_str(
        "        assert!(result.is_ok(), \"JIT T2 deserialize failed: {:?}\", result.err());\n",
    );
    output.push_str("    }\n\n");

    // SERIALIZE tests
    output.push_str("    // ===== SERIALIZE TESTS =====\n\n");

    // serde_json serialize
    output.push_str("    #[test]\n");
    output.push_str("    fn test_serde_json_serialize() {\n");
    output.push_str("        let result = serde_json::to_string(&*DATA);\n");
    output.push_str(
        "        assert!(result.is_ok(), \"serde_json serialize failed: {:?}\", result.err());\n",
    );
    output.push_str("    }\n\n");

    // facet_format_json serialize
    output.push_str("    #[test]\n");
    output.push_str("    fn test_facet_format_json_serialize() {\n");
    output.push_str("        let result = facet_format_json::to_string(&*DATA);\n");
    output.push_str("        assert!(result.is_ok(), \"facet_format_json serialize failed: {:?}\", result.err());\n");
    output.push_str("    }\n");

    output.push_str("}\n\n");
    Ok(output)
}

fn get_json_content(
    bench_def: &BenchmarkDef,
    workspace_root: &Path,
) -> Result<String, Box<dyn std::error::Error>> {
    if let Some(ref json_data) = bench_def.json {
        Ok(json_data.content.clone())
    } else if let Some(ref json_file) = bench_def.json_file {
        // Read JSON from file (relative to facet-json/benches/)
        let file_path = workspace_root
            .join("facet-json/benches")
            .join(&json_file.path);
        fs::read_to_string(&file_path)
            .map_err(|e| format!("Failed to read {}: {}", file_path.display(), e).into())
    } else if let Some(ref generated) = bench_def.generated {
        generate_json_data(&generated.generator_name)
    } else {
        Err("Benchmark must have 'json', 'json_file', 'json_brotli', or 'generated'".into())
    }
}

/// Generate JSON data for well-known benchmark patterns.
/// This runs at codegen time, so the data is embedded in the generated benchmark.
fn generate_json_data(generator_name: &str) -> Result<String, Box<dyn std::error::Error>> {
    match generator_name {
        "booleans" => {
            // 10,000 alternating booleans
            let data: Vec<bool> = (0..10000).map(|i| i % 2 == 0).collect();
            Ok(serde_json::to_string(&data)?)
        }
        "integers" => {
            // 1,000 large integers
            let data: Vec<u64> = (0..1000).map(|i| i * 12345678901234).collect();
            Ok(serde_json::to_string(&data)?)
        }
        "floats" => {
            // 1,000 floats
            let data: Vec<f64> = (0..1000).map(|i| i as f64 * 1.23456789).collect();
            Ok(serde_json::to_string(&data)?)
        }
        "short_strings" => {
            // 1,000 short strings (~10 chars each)
            let data: Vec<String> = (0..1000).map(|i| format!("str_{:06}", i)).collect();
            Ok(serde_json::to_string(&data)?)
        }
        "long_strings" => {
            // 100 long strings (1000 chars each)
            let data: Vec<String> = (0..100)
                .map(|i| "x".repeat(1000) + &format!("_{}", i))
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "escaped_strings" => {
            // 1,000 strings with escape characters
            let data: Vec<String> = (0..1000)
                .map(|i| format!("line_{}\nwith\ttabs\tand \"quotes\" and \\backslashes\\", i))
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "hashmaps" => {
            // 1,000 key-value pairs
            let data: std::collections::HashMap<String, u64> =
                (0..1000).map(|i| (format!("key_{}", i), i * 2)).collect();
            Ok(serde_json::to_string(&data)?)
        }
        "nested_structs" => {
            // 500 nested structs - generate as JSON directly
            let data: Vec<serde_json::Value> = (0..500)
                .map(|i| {
                    serde_json::json!({
                        "id": i,
                        "inner": {
                            "name": format!("name_{}", i),
                            "value": i as f64 * 1.5,
                            "deep": {
                                "flag": i % 2 == 0,
                                "count": i * 10
                            }
                        }
                    })
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "options" => {
            // 500 structs with optional fields
            let data: Vec<serde_json::Value> = (0..500)
                .map(|i| {
                    let mut obj = serde_json::json!({
                        "required": i,
                    });
                    if i % 2 == 0 {
                        obj["optional_string"] = serde_json::Value::String(format!("str_{}", i));
                    }
                    if i % 3 == 0 {
                        obj["optional_number"] = serde_json::Value::Number(
                            serde_json::Number::from_f64(i as f64).unwrap(),
                        );
                    }
                    obj
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "flatten_2enums" => {
            // 1000 configs with 2 flattened enums (4 combinations each)
            let data: Vec<serde_json::Value> = (0..250)
                .flat_map(|i| {
                    vec![
                        // Password + Tcp
                        serde_json::json!({
                            "name": format!("service_{}", i * 4),
                            "Password": { "password": "secret" },
                            "Tcp": { "tcp_port": 8080 }
                        }),
                        // Password + Unix
                        serde_json::json!({
                            "name": format!("service_{}", i * 4 + 1),
                            "Password": { "password": "secret" },
                            "Unix": { "socket_path": "/tmp/sock" }
                        }),
                        // Token + Tcp
                        serde_json::json!({
                            "name": format!("service_{}", i * 4 + 2),
                            "Token": { "token": "abc123", "token_expiry": 3600 },
                            "Tcp": { "tcp_port": 9090 }
                        }),
                        // Token + Unix
                        serde_json::json!({
                            "name": format!("service_{}", i * 4 + 3),
                            "Token": { "token": "xyz789", "token_expiry": 7200 },
                            "Unix": { "socket_path": "/var/run/app.sock" }
                        }),
                    ]
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "flatten_4enums" => {
            // ~1000 configs with 4 flattened enums (16 combinations each)
            let data: Vec<serde_json::Value> = (0..64)
                .flat_map(|batch| {
                    // Generate all 16 combinations
                    let auths = [
                        serde_json::json!({"Password": {"password": "secret"}}),
                        serde_json::json!({"Token": {"token": "abc123", "token_expiry": 3600}}),
                    ];
                    let transports = [
                        serde_json::json!({"Tcp": {"tcp_port": 8080}}),
                        serde_json::json!({"Unix": {"socket_path": "/tmp/sock"}}),
                    ];
                    let storages = [
                        serde_json::json!({"Local": {"local_path": "/data"}}),
                        serde_json::json!({"Remote": {"remote_url": "https://example.com"}}),
                    ];
                    let loggings = [
                        serde_json::json!({"File": {"log_path": "/var/log/app.log"}}),
                        serde_json::json!({"Stdout": {"log_color": true}}),
                    ];

                    let mut configs = Vec::with_capacity(16);
                    let mut idx = 0;
                    for auth in &auths {
                        for transport in &transports {
                            for storage in &storages {
                                for logging in &loggings {
                                    let mut obj = serde_json::json!({
                                        "name": format!("service_{}_{}", batch, idx),
                                    });
                                    // Merge flattened fields
                                    if let serde_json::Value::Object(m) = auth {
                                        for (k, v) in m {
                                            obj[k] = v.clone();
                                        }
                                    }
                                    if let serde_json::Value::Object(m) = transport {
                                        for (k, v) in m {
                                            obj[k] = v.clone();
                                        }
                                    }
                                    if let serde_json::Value::Object(m) = storage {
                                        for (k, v) in m {
                                            obj[k] = v.clone();
                                        }
                                    }
                                    if let serde_json::Value::Object(m) = logging {
                                        for (k, v) in m {
                                            obj[k] = v.clone();
                                        }
                                    }
                                    configs.push(obj);
                                    idx += 1;
                                }
                            }
                        }
                    }
                    configs
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        // ====== Stage 2 Priority 1: Performance Profiling Payloads ======
        "wide_struct_50" => {
            // Single wide struct with 50 scalar fields - stresses key dispatch
            let mut obj = serde_json::Map::new();
            for i in 0..10 {
                obj.insert(
                    format!("field_{:02}", i),
                    serde_json::json!(i as u64 * 1000),
                );
            }
            for i in 10..20 {
                obj.insert(
                    format!("field_{:02}", i),
                    serde_json::json!(format!("string_{}", i)),
                );
            }
            for i in 20..30 {
                obj.insert(format!("field_{:02}", i), serde_json::json!(i as f64 * 1.5));
            }
            for i in 30..40 {
                obj.insert(format!("field_{:02}", i), serde_json::json!(i % 2 == 0));
            }
            for i in 40..50 {
                obj.insert(
                    format!("field_{:02}", i),
                    serde_json::json!(i as i64 * -100),
                );
            }
            Ok(serde_json::to_string(&obj)?)
        }
        "wide_struct_63" => {
            // 63 fields total: 50 required + 13 optional (max for u64 bitmask)
            let mut obj = serde_json::Map::new();
            // field_00-15: u64 (required)
            for i in 0..16 {
                obj.insert(
                    format!("field_{:02}", i),
                    serde_json::json!(i as u64 * 1000),
                );
            }
            // field_16-31: String (required)
            for i in 16..32 {
                obj.insert(
                    format!("field_{:02}", i),
                    serde_json::json!(format!("string_{}", i)),
                );
            }
            // field_32-47: f64 (required)
            for i in 32..48 {
                obj.insert(format!("field_{:02}", i), serde_json::json!(i as f64 * 1.5));
            }
            // field_48-49: bool (required)
            for i in 48..50 {
                obj.insert(format!("field_{:02}", i), serde_json::json!(i % 2 == 0));
            }
            // field_50-62: Option<bool>, Option<i64> (optional, include ~half)
            for i in 50..63 {
                if i % 2 == 0 {
                    if i < 58 {
                        obj.insert(format!("field_{:02}", i), serde_json::json!(i % 3 == 0));
                    } else {
                        obj.insert(format!("field_{:02}", i), serde_json::json!(i as i64 * 100));
                    }
                }
            }
            Ok(serde_json::to_string(&obj)?)
        }
        "unknown_fields" => {
            // 100 objects with 10 known fields + 40 unknown fields each - stresses skip logic
            let data: Vec<serde_json::Value> = (0..100)
                .map(|i| {
                    let mut obj = serde_json::json!({
                        // 10 known fields
                        "id": i,
                        "name": format!("record_{}", i),
                        "value": i as f64 * 1.5,
                        "active": i % 2 == 0,
                        "count": i * 10,
                        "score": i as f64 * 2.5,
                        "enabled": i % 3 == 0,
                        "index": i * 2,
                        "label": format!("label_{}", i),
                        "flag": i % 5 == 0,
                    });
                    // Add 40 unknown fields that won't be in SmallStruct
                    for j in 0..40 {
                        obj[format!("unknown_{:02}", j)] =
                            serde_json::json!(format!("ignored_{}", j));
                    }
                    obj
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "deep_nesting_5levels" => {
            // Single deeply nested struct (5 levels) - stresses function call overhead
            let obj = serde_json::json!({
                "id": 1,
                "data": "level1",
                "nested": {
                    "value": 1.5,
                    "flag": true,
                    "nested": {
                        "count": 42,
                        "name": "level3",
                        "nested": {
                            "x": 3.14,
                            "y": 2.71,
                            "nested": {
                                "leaf_id": 999,
                                "leaf_value": "bottom",
                                "leaf_flag": false
                            }
                        }
                    }
                }
            });
            Ok(serde_json::to_string(&obj)?)
        }
        "large_strings_escaped" => {
            // 50 large strings (1KB-10KB) with escape sequences - stresses string decode
            let data: Vec<String> = (0..50)
                .map(|i| {
                    let size = 1024 + (i * 200); // Vary from 1KB to ~11KB
                    let chunk = "line with\nnewlines and\ttabs and \"quotes\" and \\backslashes\\ ";
                    let repeats = size / chunk.len();
                    chunk.repeat(repeats) + &format!("_{}", i)
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "large_strings_unescaped" => {
            // 50 large strings (1KB-10KB) without escapes - stresses raw string copy
            let data: Vec<String> = (0..50)
                .map(|i| {
                    let size = 1024 + (i * 200); // Vary from 1KB to ~11KB
                    "x".repeat(size) + &format!("_{}", i)
                })
                .collect();
            Ok(serde_json::to_string(&data)?)
        }
        "big_array_10k" => {
            // 10,000 integers - stresses bulk operations and Vec growth
            let data: Vec<i64> = (0..10000).map(|i| i * 123456789).collect();
            Ok(serde_json::to_string(&data)?)
        }
        _ => Err(format!("Unknown generator: {}", generator_name).into()),
    }
}
